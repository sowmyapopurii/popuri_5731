{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The second In-class-exercise (09/22/2022, 40 points in total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPlease write you answer here:\\n\\n. The research question I have to analyse is the prices of Mens casual shoes available in eBay which is an e-commerce website.\\n. For this, I have to collect the prices of the costumes that are visible to users from website by filtering the results \\nusing Mens casual shoes.\\n. There are 746K results for the search Mens casual shoes.\\n. We can collect the data and then plot to analyse the price range and high price, low price as analysis.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
    "\n",
    "'''\n",
    "Please write you answer here:\n",
    "\n",
    ". The research question I have to analyse is the prices of Mens casual shoes available in eBay which is an e-commerce website.\n",
    ". For this, I have to collect the prices of the costumes that are visible to users from website by filtering the results \n",
    "using Mens casual shoes.\n",
    ". There are 746K results for the search Mens casual shoes.\n",
    ". We can collect the data and then plot to analyse the price range and high price, low price as analysis.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Price\n",
      "0  $32.99\n",
      "1  $27.50\n",
      "2  $34.99\n",
      "3  $38.99\n",
      "4  $29.99\n",
      "(432, 1)\n"
     ]
    }
   ],
   "source": [
    "# You code here (Please add comments in the code):\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import HTTPError\n",
    "import pandas as pd\n",
    "\n",
    "prices = {\"Price\": []}\n",
    "main_url = \"https://www.ebay.com/b/Mens-Casual-Shoes/24087/bn_57235?_pgn={}\"\n",
    "for page_num in range(1, 10):\n",
    "\n",
    "    link = Request(main_url.format(page_num), headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    url = urlopen(link)\n",
    "\n",
    "    data = url.read()\n",
    "    data_soup = BeautifulSoup(data)\n",
    "    for price in data1_soup.find_all(\"span\", attrs={'class':'s-item__price'}):\n",
    "        prices['Price'].append(price.text.replace(\"\\t\", \"\"))\n",
    "        \n",
    "df = pd.DataFrame(prices)\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).\n",
    "\n",
    "The following information of the article needs to be collected:\n",
    "\n",
    "(1) Title\n",
    "\n",
    "(2) Venue/journal/conference being published\n",
    "\n",
    "(3) Year\n",
    "\n",
    "(4) Authors\n",
    "\n",
    "(5) Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "                                               Title  \\\n",
      "0                              Information Retrieval   \n",
      "1                       Modern Information Retrieval   \n",
      "2                      Private Information Retrieval   \n",
      "3           An Introduction to Information Retrieval   \n",
      "4  Naive (Bayes) at Forty: The Independence Assum...   \n",
      "\n",
      "                                   Authors  Year  \\\n",
      "0                        C.J.vanRijsbergen  1979   \n",
      "1  RicardoBaeza-Yates,BerthierRibeiro-Neto  1999   \n",
      "2                          BennyChor,etal.     0   \n",
      "3               ChristopherD.Manning,etal.  2007   \n",
      "4                             DavidD.Lewis  1998   \n",
      "\n",
      "                                            Abstract  \n",
      "0                                        \"...   ...\"  \n",
      "1  \"... Information retrieval (IR) has changed co...  \n",
      "2  \"...   We describe schemes that enable a user ...  \n",
      "3                                        \"...   ...\"  \n",
      "4  \"... The naive Bayes classifier, currently exp...  \n",
      "(500, 4)\n"
     ]
    }
   ],
   "source": [
    "# You code here (Please add comments in the code):\n",
    "    \n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import HTTPError\n",
    "import json\n",
    "import re\n",
    "total_count = 0\n",
    "count = 0\n",
    "\n",
    "result_dict = {\"Title\":[], \"Authors\":[], \"Year\":[], \"Abstract\":[]}\n",
    "main_url = \"https://citeseerx.ist.psu.edu/search?q=information+retrieval&t=doc&sort=rlv&start={}\"\n",
    "for page_num in range(0, 5000, 10):\n",
    "    link = Request(main_url.format(page_num), headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    url = urlopen(link)\n",
    "\n",
    "    data = url.read()\n",
    "    data_soup = BeautifulSoup(data)\n",
    "    \n",
    "    for i in data_soup.find_all(\"a\", attrs={'class':'remove doc_details'}):\n",
    "        result_dict[\"Title\"].append(i.text.strip())\n",
    "        \n",
    "    for i in data_soup.find_all(\"div\", attrs={'class':'pubinfo'}):\n",
    "        if len(i.find_all(\"span\")) < 2:\n",
    "            result_dict[\"Authors\"].append(i.find_all(\"span\")[0].text.replace(\" \", \"\").replace(\"\\n\", \" \").split()[1])\n",
    "            result_dict['Year'].append(0)\n",
    "\n",
    "        elif len(i.find_all(\"span\")) > 2:\n",
    "            result_dict[\"Authors\"].append(i.find_all(\"span\")[0].text.replace(\" \", \"\").replace(\"\\n\", \" \").split()[1])\n",
    "            result_dict['Year'].append(i.find_all(\"span\")[2].text.split()[1])\n",
    "        \n",
    "        else:\n",
    "            result_dict[\"Authors\"].append(i.find_all(\"span\")[0].text.replace(\" \", \"\").replace(\"\\n\", \" \").split()[1])\n",
    "            result_dict['Year'].append(i.find_all(\"span\")[1].text.split()[1])\n",
    "    for i in data_soup.find_all(\"div\", attrs={'class':'snippet'}):\n",
    "        result_dict[\"Abstract\"].append(i.text)\n",
    "\n",
    "    \n",
    "print(len(result_dict[\"Title\"]))\n",
    "print(len(result_dict[\"Authors\"]))\n",
    "print(len(result_dict[\"Year\"]))\n",
    "print(len(result_dict[\"Abstract\"]))\n",
    "result_df = pd.DataFrame(result_dict)\n",
    "print(result_df.head())\n",
    "print(result_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
    "\n",
    "The following information needs to be collected:\n",
    "\n",
    "(1) User_name\n",
    "\n",
    "(2) Posted time\n",
    "\n",
    "(3) Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @BasicAppleGuy: Checking my iPhone 14 Battery Health‚Ä¶ https://t.co/SaPgMq6GkE\n",
      "2022-09-25 17:02:00+00:00\n",
      "\n",
      "Is that an iPhone 5? https://t.co/lxBkGBKoSj\n",
      "2022-09-25 17:02:00+00:00\n",
      "\n",
      "Mandatory iPhone upgrade tweet. #iphone13\n",
      "2022-09-25 17:01:59+00:00\n",
      "\n",
      "@burakuyar4 ƒ∞Phone 17üòÇ\n",
      "2022-09-25 17:01:54+00:00\n",
      "\n",
      "RT @Sexy_Titan: @oluwapundittt At least, my money for the iPhone is set boss mi ü§≤üèΩ\n",
      "2022-09-25 17:01:51+00:00\n",
      "\n",
      "RT @nftbadger: When you drop your friend‚Äôs new iphone https://t.co/aZvg2VcdV8\n",
      "2022-09-25 17:01:49+00:00\n",
      "\n",
      "i will always be 2 iphone models behind. idc\n",
      "2022-09-25 17:01:47+00:00\n",
      "\n",
      "RT @oluwapundittt: Why do female like iPhone Max series. I barely see a lady using the normal iPhone, it has to be Max. That shit too big\n",
      "2022-09-25 17:01:47+00:00\n",
      "\n",
      "@a_clovert It depends actually cause if it's for picture quality no one comes close to the pixel but In terms of vi‚Ä¶ https://t.co/TG6O09Y1eJ\n",
      "2022-09-25 17:01:47+00:00\n",
      "\n",
      "RT @Atheist_Krishna: Pic 1: When you ask dad for iPhone\n",
      "Pic 2: When you ask dad for books https://t.co/tluazHlAVH\n",
      "2022-09-25 17:01:47+00:00\n",
      "\n",
      "RT @lhedien: The trails in the #Italian üáÆüáπ #Dolomites ü•æ‚ù§Ô∏è. Gorgeous area. üèî#italy #alps #mountains #landscapephotography #nature #beautiful‚Ä¶\n",
      "2022-09-25 17:01:47+00:00\n",
      "\n",
      "Iphone removed forex platforms MT4 and MT5 . \n",
      "Will they come to crypto exchanges too? \n",
      "\n",
      "Remember forex is a much mu‚Ä¶ https://t.co/DPzE2OQZfL\n",
      "2022-09-25 17:01:47+00:00\n",
      "\n",
      "@sparkybwoi @Guyfromtrenches If you can't respect iPhone user atleast respect iPhone ü§∑\n",
      "2022-09-25 17:01:46+00:00\n",
      "\n",
      "IN22092409500350702165 Complaint ID. In the running #BigBillionDaySale by @Flipkart @FlipkartStories i have ordered‚Ä¶ https://t.co/ovG3fbkVCF\n",
      "2022-09-25 17:01:44+00:00\n",
      "\n",
      "bruh sangah was literally directing this play through her iphone üòÇüòÇüòÇ #LittleWomenEp8\n",
      "2022-09-25 17:01:39+00:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "key= '2Em7SxlX9jPMfL4x97r3zMO0x'\n",
    "secret= 'sVbJzekKuiAgq83Y7gCwNVbSowqQokGVzWexKHl2cXIPceWtSd'\n",
    "token= '1439767876962029572-uUMt8oWRyzj9ilE5zk4uYbL93sCMPT'\n",
    "access= 'oydIGymn9bS767FVEMawE9GyGAnMmBJfaY2XXKmHnmliF'\n",
    "\n",
    "# Creating the authentication object\n",
    "auth = tweepy.OAuthHandler(key, secret)\n",
    "\n",
    "# Setting your access token and secret\n",
    "auth.set_access_token(token, access)\n",
    "\n",
    "# Creating the API object while passing in auth information\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "for tweets in api.search_tweets(q=\"iphone\", lang=\"en\"):\n",
    "    print(tweets.text)\n",
    "    print(tweets.created_at)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
